{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cosin\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "import keras.backend as K\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import seaborn as sns\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "put_data = pd.read_csv('Putin1.csv', delimiter=';', names=range(4000))\n",
    "nav_data = pd.read_csv('Navalny1.csv', delimiter=';', names=range(4000))\n",
    "put_test = pd.read_csv('Putin_test.csv', delimiter=';', names=range(4000))\n",
    "nav_test = pd.read_csv('Navalny_test.csv', delimiter=';', names=range(4000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6760"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "put_num = put_data.shape[0]\n",
    "put_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1957"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nav_num = nav_data.shape[0]\n",
    "nav_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "969"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "put_test_num = put_test.shape[0]\n",
    "put_test_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "538"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nav_test_num = nav_test.shape[0]\n",
    "nav_test_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat((put_data.iloc[:1957,:], nav_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3914, 4000)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1722</th>\n",
       "      <th>1723</th>\n",
       "      <th>1724</th>\n",
       "      <th>1725</th>\n",
       "      <th>1726</th>\n",
       "      <th>1727</th>\n",
       "      <th>1728</th>\n",
       "      <th>1729</th>\n",
       "      <th>1730</th>\n",
       "      <th>1731</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>473365518</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-50498710</td>\n",
       "      <td>-49606842</td>\n",
       "      <td>-48928605</td>\n",
       "      <td>-16389388</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>800930</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-106564427</td>\n",
       "      <td>-9758</td>\n",
       "      <td>-160937227</td>\n",
       "      <td>-26419239</td>\n",
       "      <td>-70365191</td>\n",
       "      <td>-25653235</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>346505303</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-131188697</td>\n",
       "      <td>-64299218</td>\n",
       "      <td>-123775571</td>\n",
       "      <td>-106823150</td>\n",
       "      <td>-61484302</td>\n",
       "      <td>-151336239</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>307080832</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-43776317</td>\n",
       "      <td>-57846937</td>\n",
       "      <td>-62965884</td>\n",
       "      <td>-70870022</td>\n",
       "      <td>-23951627</td>\n",
       "      <td>-124305154</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>404314502</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>-113801785</td>\n",
       "      <td>-6726778</td>\n",
       "      <td>-17568841</td>\n",
       "      <td>-94686473</td>\n",
       "      <td>-159187081</td>\n",
       "      <td>-161812969</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1732 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2     3          4         5          6          7     \\\n",
       "0  473365518    20     2    -1  -50498710 -49606842  -48928605  -16389388   \n",
       "1     800930    36     2    -1 -106564427     -9758 -160937227  -26419239   \n",
       "2  346505303    -1     2    -1 -131188697 -64299218 -123775571 -106823150   \n",
       "3  307080832    21     2    -1  -43776317 -57846937  -62965884  -70870022   \n",
       "4  404314502    -1     2     5 -113801785  -6726778  -17568841  -94686473   \n",
       "\n",
       "        8          9     ...   1722  1723  1724  1725  1726  1727  1728  1729  \\\n",
       "0          0          0  ...      0     0     0     0     0     0     0     0   \n",
       "1  -70365191  -25653235  ...      0     0     0     0     0     0     0     0   \n",
       "2  -61484302 -151336239  ...      0     0     0     0     0     0     0     0   \n",
       "3  -23951627 -124305154  ...      0     0     0     0     0     0     0     0   \n",
       "4 -159187081 -161812969  ...      0     0     0     0     0     0     0     0   \n",
       "\n",
       "   1730  1731  \n",
       "0     0     0  \n",
       "1     0     0  \n",
       "2     0     0  \n",
       "3     0     0  \n",
       "4     0     0  \n",
       "\n",
       "[5 rows x 1732 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna(axis=1, how='all', inplace=True)\n",
    "data.fillna(0, inplace=True) # replacing NaNs with zeros\n",
    "data = data.applymap(int)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127235,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publics = np.unique(data.iloc[:, 4:].values) # list of publics\n",
    "publics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127234,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publics = np.delete(publics, np.where(publics == 0)[0]) # deleting id=0\n",
    "publics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127234,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counters = np.zeros(publics.shape[0])\n",
    "counters.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  0,  1,  2], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genders = np.unique(data.iloc[:, 2]) # list of genders\n",
    "genders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1,  2,  3,  4,  5,  6,  7,  8,  9], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preferences = np.unique(data.iloc[:, 3]) # list of political preferences\n",
    "preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3914"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_num = data.shape[0] # number of users in dataset\n",
    "users_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ages=[0, 18, 26, 36, 51, 66, 86]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ages = np.zeros([users_num, len(Ages)+1], dtype=np.float16)\n",
    "X_sex = np.zeros([users_num, genders.shape[0]], dtype=np.float16)\n",
    "X_pref = np.zeros([users_num, preferences.shape[0]], dtype=np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3913/3914\r"
     ]
    }
   ],
   "source": [
    "for i in range(users_num):\n",
    "    print(str(i)+'/'+str(users_num), end='\\r')\n",
    "    age = data.iloc[i, 1]\n",
    "    sex = data.iloc[i, 2]\n",
    "    pref = data.iloc[i, 3]\n",
    "    publ = data.iloc[i, 4:]\n",
    "    \n",
    "    for a in range(len(Ages)): # filling X_ages\n",
    "        if age < Ages[a]:\n",
    "            X_ages[i, a] = 1\n",
    "            break\n",
    "        elif age >= Ages[len(Ages)-1]:\n",
    "            X_ages[i, len(Ages)] = 1\n",
    "            break\n",
    "    \n",
    "    for j in range(genders.shape[0]): # filling genders\n",
    "        if sex == genders[j]:\n",
    "            X_sex[i, j] = 1\n",
    "    \n",
    "    for j in range(preferences.shape[0]): # filling preferences\n",
    "        if pref == preferences[j]:\n",
    "            X_pref[i, j] = 1\n",
    "    \n",
    "    for j in publ: # counting the number of occurence of each public\n",
    "        if j == 0:\n",
    "            break\n",
    "        publ_index = np.where(publics == j)[0][0]\n",
    "        counters[publ_index] = counters[publ_index] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activaton(ind): # for taking into account the order of publics\n",
    "    return 1/(1+np.exp(0.2*ind)) + 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3913/3914\r"
     ]
    }
   ],
   "source": [
    "X_publ = []\n",
    "X_publ = np.zeros([users_num, publics.shape[0]], dtype=np.float16)\n",
    "for i in range(users_num):\n",
    "    print(str(i)+'/'+str(users_num), end='\\r')\n",
    "    publ = data.iloc[i, 4:].values\n",
    "    for j in range(publ.shape[0]):\n",
    "        if publ[j] == 0:\n",
    "            break\n",
    "        publ_index = np.where(publics == publ[j])[0]\n",
    "        X_publ[i, publ_index] = activaton(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3914, 127256)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.hstack((X_ages, X_sex, X_pref, X_publ)) # merging all arrays into one\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA components\n",
    "n_components = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=42) # cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=14, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=n_components)\n",
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib # saving pca\n",
    "_ = joblib.dump(pca, 'pcaPutNav.save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cosin\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n"
     ]
    }
   ],
   "source": [
    "X_pca = pca.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1507"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = pd.concat((put_test, nav_test))\n",
    "num = data_test.shape[0]\n",
    "num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>200</th>\n",
       "      <th>201</th>\n",
       "      <th>202</th>\n",
       "      <th>203</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>330864174</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-58798248</td>\n",
       "      <td>-35145657</td>\n",
       "      <td>-57846937</td>\n",
       "      <td>-83876626</td>\n",
       "      <td>-84429649</td>\n",
       "      <td>-60397113</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>217809018</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-142754704</td>\n",
       "      <td>-66621324</td>\n",
       "      <td>-70204174</td>\n",
       "      <td>-54154078</td>\n",
       "      <td>-77963997</td>\n",
       "      <td>-23064236</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20671231</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-133742557</td>\n",
       "      <td>-40836944</td>\n",
       "      <td>-22798006</td>\n",
       "      <td>-60443553</td>\n",
       "      <td>-88759692</td>\n",
       "      <td>-125303834</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>366089932</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-116871226</td>\n",
       "      <td>-133791433</td>\n",
       "      <td>-83985614</td>\n",
       "      <td>-126506885</td>\n",
       "      <td>-142918020</td>\n",
       "      <td>-122181832</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>399763476</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-39399586</td>\n",
       "      <td>-135646310</td>\n",
       "      <td>-58170807</td>\n",
       "      <td>-100954660</td>\n",
       "      <td>-15326149</td>\n",
       "      <td>-111205860</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 204 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0    1    2    3          4          5         6          7    \\\n",
       "0  330864174   -1    2   -1  -58798248  -35145657 -57846937  -83876626   \n",
       "1  217809018   28    2   -1 -142754704  -66621324 -70204174  -54154078   \n",
       "2   20671231   30    2   -1 -133742557  -40836944 -22798006  -60443553   \n",
       "3  366089932   15    1   -1 -116871226 -133791433 -83985614 -126506885   \n",
       "4  399763476   -1    2   -1  -39399586 -135646310 -58170807 -100954660   \n",
       "\n",
       "         8          9   ...   194  195  196  197  198  199  200  201  202  203  \n",
       "0  -84429649  -60397113 ...     0    0    0    0    0    0    0    0    0    0  \n",
       "1  -77963997  -23064236 ...     0    0    0    0    0    0    0    0    0    0  \n",
       "2  -88759692 -125303834 ...     0    0    0    0    0    0    0    0    0    0  \n",
       "3 -142918020 -122181832 ...     0    0    0    0    0    0    0    0    0    0  \n",
       "4  -15326149 -111205860 ...     0    0    0    0    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 204 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.dropna(axis=1, how='all', inplace=True)\n",
    "data_test.fillna(0, inplace=True) # replacing NaNs with zeros\n",
    "data_test = data_test.applymap(int)\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ages = np.zeros([num, len(Ages)+1], dtype=np.float16)\n",
    "X_sex = np.zeros([num, genders.shape[0]], dtype=np.float16)\n",
    "X_pref = np.zeros([num, preferences.shape[0]], dtype=np.float16)\n",
    "X_publ = np.zeros([num, publics.shape[0]], dtype=np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1506/1507\r"
     ]
    }
   ],
   "source": [
    "for i in range(num):\n",
    "    print(str(i)+'/'+str(num), end='\\r')\n",
    "    age = data_test.iloc[i, 1]\n",
    "    sex = data_test.iloc[i, 2]\n",
    "    pref = data_test.iloc[i, 3]\n",
    "    publ = data_test.iloc[i, 4:]\n",
    "    \n",
    "    for a in range(len(Ages)): # filling X_ages\n",
    "        if age < Ages[a]:\n",
    "            X_ages[i, a] = 1\n",
    "            break\n",
    "        elif age >= Ages[len(Ages)-1]:\n",
    "            X_ages[i, len(Ages)] = 1\n",
    "            break\n",
    "    \n",
    "    for j in range(genders.shape[0]): # filling genders\n",
    "        if sex == genders[j]:\n",
    "            X_sex[i, j] = 1\n",
    "    \n",
    "    for j in range(preferences.shape[0]): # filling preferences\n",
    "        if pref == preferences[j]:\n",
    "            X_pref[i, j] = 1\n",
    "    \n",
    "    for j in range(publ.shape[0]):\n",
    "        if publ.values[j] == 0:\n",
    "            break\n",
    "        publ_index = np.where(publics == publ.values[j])[0]\n",
    "        X_publ[i, publ_index] = activaton(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1507, 127256)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = np.hstack((X_ages, X_sex, X_pref, X_publ)) # merging all arrays into one\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1507, 14)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('trainPutNavPCA.npy', X_pca)\n",
    "np.save('testPutNavPCA.npy', X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.append(np.zeros(nav_num), np.ones(nav_num))\n",
    "y_test = np.append(np.zeros(put_test_num), np.ones(nav_test_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3914,)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN hyperparameters\n",
    "batch_size = 600\n",
    "epochs = 200\n",
    "dropout_size = 0.5\n",
    "\n",
    "# hidden layers dimensions\n",
    "hidden_first = 50\n",
    "hidden_second = 25\n",
    "hidden_third = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3914 samples, validate on 1077 samples\n",
      "Epoch 1/200\n",
      "3914/3914 [==============================] - 5s 1ms/step - loss: 0.6706 - acc: 0.6022 - val_loss: 0.6754 - val_acc: 0.5590\n",
      "Epoch 2/200\n",
      "3914/3914 [==============================] - 0s 25us/step - loss: 0.6466 - acc: 0.6903 - val_loss: 0.6609 - val_acc: 0.6110\n",
      "Epoch 3/200\n",
      "3914/3914 [==============================] - 0s 23us/step - loss: 0.6142 - acc: 0.7976 - val_loss: 0.6422 - val_acc: 0.6453\n",
      "Epoch 4/200\n",
      "3914/3914 [==============================] - 0s 20us/step - loss: 0.5686 - acc: 0.8679 - val_loss: 0.6191 - val_acc: 0.6713\n",
      "Epoch 5/200\n",
      "3914/3914 [==============================] - 0s 22us/step - loss: 0.5138 - acc: 0.9144 - val_loss: 0.5936 - val_acc: 0.6908\n",
      "Epoch 6/200\n",
      "3914/3914 [==============================] - 0s 24us/step - loss: 0.4550 - acc: 0.9280 - val_loss: 0.5698 - val_acc: 0.7038\n",
      "Epoch 7/200\n",
      "3914/3914 [==============================] - 0s 24us/step - loss: 0.3963 - acc: 0.9325 - val_loss: 0.5505 - val_acc: 0.7112\n",
      "Epoch 8/200\n",
      "3914/3914 [==============================] - 0s 23us/step - loss: 0.3410 - acc: 0.9359 - val_loss: 0.5370 - val_acc: 0.7196\n",
      "Epoch 9/200\n",
      "3914/3914 [==============================] - 0s 24us/step - loss: 0.2922 - acc: 0.9377 - val_loss: 0.5298 - val_acc: 0.7224\n",
      "Epoch 10/200\n",
      "3914/3914 [==============================] - 0s 23us/step - loss: 0.2515 - acc: 0.9394 - val_loss: 0.5249 - val_acc: 0.7307\n",
      "Epoch 11/200\n",
      "3914/3914 [==============================] - 0s 24us/step - loss: 0.2195 - acc: 0.9412 - val_loss: 0.5235 - val_acc: 0.7382\n",
      "Epoch 12/200\n",
      "3914/3914 [==============================] - 0s 23us/step - loss: 0.1955 - acc: 0.9440 - val_loss: 0.5212 - val_acc: 0.7428\n",
      "Epoch 13/200\n",
      "3914/3914 [==============================] - 0s 21us/step - loss: 0.1776 - acc: 0.9456 - val_loss: 0.5254 - val_acc: 0.7502\n",
      "Epoch 14/200\n",
      "3914/3914 [==============================] - 0s 25us/step - loss: 0.1645 - acc: 0.9479 - val_loss: 0.5288 - val_acc: 0.7521\n",
      "Epoch 15/200\n",
      "3914/3914 [==============================] - 0s 24us/step - loss: 0.1546 - acc: 0.9489 - val_loss: 0.5296 - val_acc: 0.7577\n",
      "Epoch 16/200\n",
      "3914/3914 [==============================] - 0s 24us/step - loss: 0.1470 - acc: 0.9484 - val_loss: 0.5387 - val_acc: 0.7614\n",
      "Epoch 17/200\n",
      "3914/3914 [==============================] - 0s 26us/step - loss: 0.1407 - acc: 0.9497 - val_loss: 0.5367 - val_acc: 0.7642\n",
      "Epoch 18/200\n",
      "3914/3914 [==============================] - 0s 27us/step - loss: 0.1363 - acc: 0.9504 - val_loss: 0.5435 - val_acc: 0.7660\n",
      "Epoch 19/200\n",
      "3914/3914 [==============================] - 0s 23us/step - loss: 0.1323 - acc: 0.9517 - val_loss: 0.5520 - val_acc: 0.7679\n",
      "Epoch 20/200\n",
      "3914/3914 [==============================] - 0s 22us/step - loss: 0.1291 - acc: 0.9522 - val_loss: 0.5549 - val_acc: 0.7679\n",
      "Epoch 21/200\n",
      "3914/3914 [==============================] - 0s 22us/step - loss: 0.1265 - acc: 0.9538 - val_loss: 0.5611 - val_acc: 0.7679\n",
      "Epoch 22/200\n",
      "3914/3914 [==============================] - 0s 20us/step - loss: 0.1241 - acc: 0.9545 - val_loss: 0.5672 - val_acc: 0.7716\n",
      "Epoch 23/200\n",
      "3914/3914 [==============================] - 0s 22us/step - loss: 0.1226 - acc: 0.9538 - val_loss: 0.5812 - val_acc: 0.7669\n",
      "Epoch 24/200\n",
      "3914/3914 [==============================] - 0s 20us/step - loss: 0.1206 - acc: 0.9561 - val_loss: 0.5656 - val_acc: 0.7799\n",
      "Epoch 25/200\n",
      "3914/3914 [==============================] - 0s 23us/step - loss: 0.1190 - acc: 0.9558 - val_loss: 0.5782 - val_acc: 0.7799\n",
      "Epoch 26/200\n",
      "3914/3914 [==============================] - 0s 23us/step - loss: 0.1176 - acc: 0.9566 - val_loss: 0.5743 - val_acc: 0.7809\n",
      "Epoch 27/200\n",
      "3914/3914 [==============================] - 0s 22us/step - loss: 0.1162 - acc: 0.9571 - val_loss: 0.5783 - val_acc: 0.7837\n",
      "Epoch 28/200\n",
      "3914/3914 [==============================] - 0s 23us/step - loss: 0.1152 - acc: 0.9576 - val_loss: 0.5803 - val_acc: 0.7837\n",
      "Epoch 29/200\n",
      "3914/3914 [==============================] - 0s 22us/step - loss: 0.1141 - acc: 0.9589 - val_loss: 0.5871 - val_acc: 0.7827\n",
      "Epoch 30/200\n",
      "3914/3914 [==============================] - 0s 22us/step - loss: 0.1131 - acc: 0.9586 - val_loss: 0.5907 - val_acc: 0.7818\n",
      "Epoch 31/200\n",
      "3914/3914 [==============================] - 0s 20us/step - loss: 0.1123 - acc: 0.9586 - val_loss: 0.5921 - val_acc: 0.7827\n",
      "Epoch 32/200\n",
      "3914/3914 [==============================] - 0s 23us/step - loss: 0.1116 - acc: 0.9594 - val_loss: 0.5772 - val_acc: 0.7902\n",
      "Epoch 33/200\n",
      "3914/3914 [==============================] - 0s 23us/step - loss: 0.1106 - acc: 0.9594 - val_loss: 0.6004 - val_acc: 0.7818\n",
      "Epoch 34/200\n",
      "3914/3914 [==============================] - 0s 24us/step - loss: 0.1098 - acc: 0.9599 - val_loss: 0.5853 - val_acc: 0.7883\n",
      "Epoch 35/200\n",
      "3914/3914 [==============================] - 0s 23us/step - loss: 0.1092 - acc: 0.9599 - val_loss: 0.5836 - val_acc: 0.7883\n",
      "Epoch 36/200\n",
      "3914/3914 [==============================] - 0s 23us/step - loss: 0.1085 - acc: 0.9601 - val_loss: 0.5909 - val_acc: 0.7892\n",
      "Epoch 37/200\n",
      "3914/3914 [==============================] - 0s 21us/step - loss: 0.1079 - acc: 0.9607 - val_loss: 0.5943 - val_acc: 0.7911\n",
      "Epoch 38/200\n",
      "3914/3914 [==============================] - 0s 20us/step - loss: 0.1073 - acc: 0.9617 - val_loss: 0.5954 - val_acc: 0.7902\n",
      "Epoch 39/200\n",
      "3914/3914 [==============================] - 0s 25us/step - loss: 0.1069 - acc: 0.9624 - val_loss: 0.5787 - val_acc: 0.7967\n",
      "Epoch 40/200\n",
      "3914/3914 [==============================] - 0s 21us/step - loss: 0.1064 - acc: 0.9624 - val_loss: 0.6082 - val_acc: 0.7892\n",
      "Epoch 41/200\n",
      "3914/3914 [==============================] - 0s 21us/step - loss: 0.1057 - acc: 0.9627 - val_loss: 0.5899 - val_acc: 0.7957\n",
      "Epoch 42/200\n",
      "3914/3914 [==============================] - 0s 21us/step - loss: 0.1054 - acc: 0.9635 - val_loss: 0.5890 - val_acc: 0.7957\n",
      "Epoch 43/200\n",
      "3914/3914 [==============================] - 0s 22us/step - loss: 0.1047 - acc: 0.9632 - val_loss: 0.6020 - val_acc: 0.7929\n",
      "Epoch 44/200\n",
      "3914/3914 [==============================] - 0s 22us/step - loss: 0.1045 - acc: 0.9622 - val_loss: 0.6005 - val_acc: 0.7957\n",
      "Epoch 45/200\n",
      "3914/3914 [==============================] - 0s 22us/step - loss: 0.1039 - acc: 0.9630 - val_loss: 0.5848 - val_acc: 0.8004\n",
      "Epoch 46/200\n",
      "3914/3914 [==============================] - 0s 22us/step - loss: 0.1036 - acc: 0.9632 - val_loss: 0.5916 - val_acc: 0.8004\n",
      "Epoch 47/200\n",
      "3914/3914 [==============================] - 0s 20us/step - loss: 0.1032 - acc: 0.9632 - val_loss: 0.5999 - val_acc: 0.7976\n",
      "Epoch 48/200\n",
      "3914/3914 [==============================] - 0s 21us/step - loss: 0.1026 - acc: 0.9635 - val_loss: 0.5844 - val_acc: 0.7994\n",
      "Epoch 49/200\n",
      "3914/3914 [==============================] - 0s 23us/step - loss: 0.1024 - acc: 0.9637 - val_loss: 0.5903 - val_acc: 0.7994\n",
      "Epoch 50/200\n",
      "3914/3914 [==============================] - 0s 22us/step - loss: 0.1019 - acc: 0.9632 - val_loss: 0.6037 - val_acc: 0.7967\n",
      "Epoch 51/200\n",
      "3914/3914 [==============================] - 0s 25us/step - loss: 0.1016 - acc: 0.9635 - val_loss: 0.5886 - val_acc: 0.8004\n",
      "Epoch 52/200\n",
      "3914/3914 [==============================] - 0s 23us/step - loss: 0.1015 - acc: 0.9640 - val_loss: 0.5907 - val_acc: 0.7994\n",
      "Epoch 53/200\n",
      "3914/3914 [==============================] - 0s 23us/step - loss: 0.1012 - acc: 0.9642 - val_loss: 0.6006 - val_acc: 0.7985\n",
      "Epoch 54/200\n",
      "3914/3914 [==============================] - 0s 21us/step - loss: 0.1007 - acc: 0.9642 - val_loss: 0.5846 - val_acc: 0.8050\n",
      "Epoch 55/200\n",
      "3914/3914 [==============================] - 0s 19us/step - loss: 0.1005 - acc: 0.9642 - val_loss: 0.5887 - val_acc: 0.8022\n",
      "Epoch 56/200\n",
      "3914/3914 [==============================] - 0s 23us/step - loss: 0.1005 - acc: 0.9642 - val_loss: 0.5962 - val_acc: 0.8004\n",
      "Epoch 57/200\n",
      "3914/3914 [==============================] - 0s 23us/step - loss: 0.0999 - acc: 0.9640 - val_loss: 0.5842 - val_acc: 0.8041\n",
      "Epoch 58/200\n",
      "3914/3914 [==============================] - 0s 24us/step - loss: 0.0997 - acc: 0.9645 - val_loss: 0.5940 - val_acc: 0.8004\n",
      "Epoch 59/200\n",
      "3914/3914 [==============================] - 0s 22us/step - loss: 0.0994 - acc: 0.9650 - val_loss: 0.5974 - val_acc: 0.8013\n",
      "Epoch 60/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3914/3914 [==============================] - 0s 24us/step - loss: 0.0989 - acc: 0.9645 - val_loss: 0.5870 - val_acc: 0.8050\n",
      "Epoch 61/200\n",
      "3914/3914 [==============================] - 0s 26us/step - loss: 0.0986 - acc: 0.9640 - val_loss: 0.5920 - val_acc: 0.8041\n",
      "Epoch 62/200\n",
      "3914/3914 [==============================] - 0s 27us/step - loss: 0.0987 - acc: 0.9642 - val_loss: 0.5879 - val_acc: 0.8050\n",
      "Epoch 63/200\n",
      "3914/3914 [==============================] - 0s 24us/step - loss: 0.0983 - acc: 0.9645 - val_loss: 0.6000 - val_acc: 0.7994\n",
      "Epoch 64/200\n",
      "3914/3914 [==============================] - 0s 25us/step - loss: 0.0978 - acc: 0.9650 - val_loss: 0.5857 - val_acc: 0.8041\n",
      "Epoch 65/200\n",
      "3914/3914 [==============================] - 0s 24us/step - loss: 0.0975 - acc: 0.9650 - val_loss: 0.5842 - val_acc: 0.8069\n",
      "Epoch 66/200\n",
      "3914/3914 [==============================] - 0s 24us/step - loss: 0.0974 - acc: 0.9653 - val_loss: 0.5889 - val_acc: 0.8050\n",
      "Epoch 67/200\n",
      "3914/3914 [==============================] - 0s 26us/step - loss: 0.0970 - acc: 0.9650 - val_loss: 0.5964 - val_acc: 0.8022\n",
      "Epoch 68/200\n",
      "3914/3914 [==============================] - 0s 27us/step - loss: 0.0971 - acc: 0.9647 - val_loss: 0.6017 - val_acc: 0.8022\n",
      "Epoch 69/200\n",
      "3914/3914 [==============================] - 0s 23us/step - loss: 0.0967 - acc: 0.9647 - val_loss: 0.5809 - val_acc: 0.8078\n",
      "Epoch 70/200\n",
      "3914/3914 [==============================] - 0s 25us/step - loss: 0.0965 - acc: 0.9655 - val_loss: 0.5888 - val_acc: 0.8069\n",
      "Epoch 71/200\n",
      "3914/3914 [==============================] - 0s 25us/step - loss: 0.0961 - acc: 0.9658 - val_loss: 0.5895 - val_acc: 0.8059\n",
      "Epoch 72/200\n",
      "3914/3914 [==============================] - 0s 26us/step - loss: 0.0958 - acc: 0.9658 - val_loss: 0.5830 - val_acc: 0.8087\n",
      "Epoch 73/200\n",
      "3914/3914 [==============================] - 0s 22us/step - loss: 0.0955 - acc: 0.9660 - val_loss: 0.5895 - val_acc: 0.8059\n",
      "Epoch 74/200\n",
      "3914/3914 [==============================] - 0s 24us/step - loss: 0.0952 - acc: 0.9658 - val_loss: 0.5952 - val_acc: 0.8041\n",
      "Epoch 75/200\n",
      "3914/3914 [==============================] - 0s 26us/step - loss: 0.0951 - acc: 0.9658 - val_loss: 0.5883 - val_acc: 0.8078\n",
      "Epoch 76/200\n",
      "3914/3914 [==============================] - 0s 24us/step - loss: 0.0952 - acc: 0.9673 - val_loss: 0.5827 - val_acc: 0.8087\n",
      "Epoch 77/200\n",
      "3914/3914 [==============================] - 0s 25us/step - loss: 0.0947 - acc: 0.9653 - val_loss: 0.5898 - val_acc: 0.8059\n",
      "Epoch 78/200\n",
      "3914/3914 [==============================] - 0s 25us/step - loss: 0.0945 - acc: 0.9673 - val_loss: 0.5812 - val_acc: 0.8106\n",
      "Epoch 79/200\n",
      "3914/3914 [==============================] - 0s 26us/step - loss: 0.0941 - acc: 0.9670 - val_loss: 0.5900 - val_acc: 0.8087\n",
      "Epoch 80/200\n",
      "3914/3914 [==============================] - 0s 19us/step - loss: 0.0939 - acc: 0.9663 - val_loss: 0.5955 - val_acc: 0.8050\n",
      "Epoch 81/200\n",
      "3914/3914 [==============================] - 0s 23us/step - loss: 0.0940 - acc: 0.9663 - val_loss: 0.5843 - val_acc: 0.8106\n",
      "Epoch 82/200\n",
      "3914/3914 [==============================] - 0s 29us/step - loss: 0.0936 - acc: 0.9663 - val_loss: 0.5887 - val_acc: 0.8087\n",
      "Epoch 83/200\n",
      "3914/3914 [==============================] - 0s 25us/step - loss: 0.0935 - acc: 0.9668 - val_loss: 0.5801 - val_acc: 0.8106\n",
      "Epoch 84/200\n",
      "3914/3914 [==============================] - 0s 21us/step - loss: 0.0932 - acc: 0.9673 - val_loss: 0.5775 - val_acc: 0.8106\n",
      "Epoch 85/200\n",
      "3914/3914 [==============================] - 0s 22us/step - loss: 0.0929 - acc: 0.9673 - val_loss: 0.5911 - val_acc: 0.8078\n",
      "Epoch 86/200\n",
      "3914/3914 [==============================] - 0s 21us/step - loss: 0.0928 - acc: 0.9668 - val_loss: 0.5890 - val_acc: 0.8078\n",
      "Epoch 87/200\n",
      "3914/3914 [==============================] - 0s 24us/step - loss: 0.0926 - acc: 0.9670 - val_loss: 0.5815 - val_acc: 0.8106\n",
      "Epoch 88/200\n",
      "3914/3914 [==============================] - 0s 24us/step - loss: 0.0925 - acc: 0.9670 - val_loss: 0.5797 - val_acc: 0.8134\n",
      "Epoch 89/200\n",
      "3914/3914 [==============================] - 0s 26us/step - loss: 0.0922 - acc: 0.9673 - val_loss: 0.5876 - val_acc: 0.8097\n",
      "Epoch 90/200\n",
      "3914/3914 [==============================] - 0s 25us/step - loss: 0.0921 - acc: 0.9673 - val_loss: 0.5842 - val_acc: 0.8115\n",
      "Epoch 91/200\n",
      "3914/3914 [==============================] - 0s 24us/step - loss: 0.0917 - acc: 0.9676 - val_loss: 0.5965 - val_acc: 0.8106\n",
      "Epoch 92/200\n",
      "3914/3914 [==============================] - 0s 22us/step - loss: 0.0918 - acc: 0.9670 - val_loss: 0.5900 - val_acc: 0.8115\n",
      "Epoch 93/200\n",
      "3914/3914 [==============================] - 0s 26us/step - loss: 0.0916 - acc: 0.9673 - val_loss: 0.5726 - val_acc: 0.8162\n",
      "Epoch 94/200\n",
      "3914/3914 [==============================] - 0s 22us/step - loss: 0.0917 - acc: 0.9668 - val_loss: 0.6022 - val_acc: 0.8059\n",
      "Epoch 95/200\n",
      "3914/3914 [==============================] - 0s 25us/step - loss: 0.0916 - acc: 0.9676 - val_loss: 0.5637 - val_acc: 0.8180\n",
      "Epoch 96/200\n",
      "3914/3914 [==============================] - 0s 20us/step - loss: 0.0907 - acc: 0.9683 - val_loss: 0.5921 - val_acc: 0.8115\n",
      "Epoch 97/200\n",
      "3914/3914 [==============================] - 0s 22us/step - loss: 0.0915 - acc: 0.9670 - val_loss: 0.5960 - val_acc: 0.8087\n",
      "Epoch 98/200\n",
      "3914/3914 [==============================] - 0s 23us/step - loss: 0.0915 - acc: 0.9686 - val_loss: 0.5618 - val_acc: 0.8171\n",
      "Epoch 99/200\n",
      "3914/3914 [==============================] - 0s 20us/step - loss: 0.0903 - acc: 0.9683 - val_loss: 0.6014 - val_acc: 0.8115\n",
      "Epoch 100/200\n",
      "3914/3914 [==============================] - 0s 21us/step - loss: 0.0908 - acc: 0.9673 - val_loss: 0.5807 - val_acc: 0.8124\n",
      "Epoch 101/200\n",
      "3914/3914 [==============================] - 0s 22us/step - loss: 0.0897 - acc: 0.9686 - val_loss: 0.5820 - val_acc: 0.8124\n",
      "Epoch 102/200\n",
      "3914/3914 [==============================] - 0s 20us/step - loss: 0.0896 - acc: 0.9683 - val_loss: 0.5902 - val_acc: 0.8124\n",
      "Epoch 103/200\n",
      "3914/3914 [==============================] - 0s 21us/step - loss: 0.0895 - acc: 0.9683 - val_loss: 0.5777 - val_acc: 0.8143\n",
      "Epoch 104/200\n",
      "3914/3914 [==============================] - 0s 22us/step - loss: 0.0895 - acc: 0.9681 - val_loss: 0.5842 - val_acc: 0.8143\n",
      "Epoch 105/200\n",
      "3914/3914 [==============================] - 0s 25us/step - loss: 0.0890 - acc: 0.9691 - val_loss: 0.5752 - val_acc: 0.8152\n",
      "Epoch 106/200\n",
      "3914/3914 [==============================] - 0s 21us/step - loss: 0.0889 - acc: 0.9686 - val_loss: 0.5844 - val_acc: 0.8124\n",
      "Epoch 107/200\n",
      "3914/3914 [==============================] - 0s 24us/step - loss: 0.0887 - acc: 0.9686 - val_loss: 0.5862 - val_acc: 0.8124\n",
      "Epoch 108/200\n",
      "3914/3914 [==============================] - 0s 22us/step - loss: 0.0885 - acc: 0.9688 - val_loss: 0.5797 - val_acc: 0.8152\n",
      "Epoch 109/200\n",
      "3914/3914 [==============================] - 0s 22us/step - loss: 0.0885 - acc: 0.9691 - val_loss: 0.5794 - val_acc: 0.8152\n",
      "Epoch 110/200\n",
      "3914/3914 [==============================] - 0s 20us/step - loss: 0.0883 - acc: 0.9686 - val_loss: 0.5813 - val_acc: 0.8124\n",
      "Epoch 111/200\n",
      "3914/3914 [==============================] - 0s 20us/step - loss: 0.0881 - acc: 0.9683 - val_loss: 0.5773 - val_acc: 0.8143\n",
      "Epoch 112/200\n",
      "3914/3914 [==============================] - 0s 26us/step - loss: 0.0876 - acc: 0.9686 - val_loss: 0.5726 - val_acc: 0.8152\n",
      "Epoch 113/200\n",
      "3914/3914 [==============================] - 0s 23us/step - loss: 0.0878 - acc: 0.9691 - val_loss: 0.5884 - val_acc: 0.8124\n",
      "Epoch 114/200\n",
      "3914/3914 [==============================] - 0s 20us/step - loss: 0.0876 - acc: 0.9686 - val_loss: 0.5871 - val_acc: 0.8134\n",
      "Epoch 115/200\n",
      "3914/3914 [==============================] - 0s 22us/step - loss: 0.0877 - acc: 0.9693 - val_loss: 0.5678 - val_acc: 0.8189\n",
      "Epoch 116/200\n",
      "3914/3914 [==============================] - 0s 24us/step - loss: 0.0880 - acc: 0.9678 - val_loss: 0.5978 - val_acc: 0.8115\n",
      "Epoch 117/200\n",
      "3914/3914 [==============================] - 0s 23us/step - loss: 0.0869 - acc: 0.9683 - val_loss: 0.5650 - val_acc: 0.8199\n",
      "Epoch 118/200\n",
      "3914/3914 [==============================] - 0s 22us/step - loss: 0.0867 - acc: 0.9693 - val_loss: 0.5895 - val_acc: 0.8124\n",
      "Epoch 119/200\n",
      "3914/3914 [==============================] - 0s 19us/step - loss: 0.0873 - acc: 0.9691 - val_loss: 0.5895 - val_acc: 0.8134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/200\n",
      "3914/3914 [==============================] - 0s 21us/step - loss: 0.0863 - acc: 0.9693 - val_loss: 0.5716 - val_acc: 0.8162\n",
      "Epoch 121/200\n",
      "3914/3914 [==============================] - 0s 22us/step - loss: 0.0864 - acc: 0.9691 - val_loss: 0.5912 - val_acc: 0.8134\n",
      "Epoch 122/200\n",
      "3914/3914 [==============================] - 0s 23us/step - loss: 0.0861 - acc: 0.9683 - val_loss: 0.5842 - val_acc: 0.8152\n",
      "Epoch 123/200\n",
      "3914/3914 [==============================] - 0s 22us/step - loss: 0.0864 - acc: 0.9699 - val_loss: 0.5711 - val_acc: 0.8189\n",
      "Epoch 124/200\n",
      "3914/3914 [==============================] - 0s 22us/step - loss: 0.0861 - acc: 0.9683 - val_loss: 0.6008 - val_acc: 0.8106\n",
      "Epoch 125/200\n",
      "3914/3914 [==============================] - 0s 27us/step - loss: 0.0853 - acc: 0.9693 - val_loss: 0.5661 - val_acc: 0.8180\n",
      "Epoch 126/200\n",
      "3914/3914 [==============================] - 0s 26us/step - loss: 0.0856 - acc: 0.9699 - val_loss: 0.5859 - val_acc: 0.8162\n",
      "Epoch 127/200\n",
      "3914/3914 [==============================] - 0s 26us/step - loss: 0.0851 - acc: 0.9691 - val_loss: 0.6016 - val_acc: 0.8124\n",
      "Epoch 128/200\n",
      "3914/3914 [==============================] - 0s 23us/step - loss: 0.0850 - acc: 0.9693 - val_loss: 0.5850 - val_acc: 0.8162\n",
      "Epoch 129/200\n",
      "3914/3914 [==============================] - 0s 24us/step - loss: 0.0847 - acc: 0.9701 - val_loss: 0.5790 - val_acc: 0.8180\n",
      "Epoch 130/200\n",
      "3914/3914 [==============================] - 0s 24us/step - loss: 0.0847 - acc: 0.9699 - val_loss: 0.5884 - val_acc: 0.8152\n",
      "Epoch 131/200\n",
      "3914/3914 [==============================] - 0s 23us/step - loss: 0.0846 - acc: 0.9693 - val_loss: 0.5963 - val_acc: 0.8134\n",
      "Epoch 132/200\n",
      "3914/3914 [==============================] - 0s 24us/step - loss: 0.0841 - acc: 0.9701 - val_loss: 0.5752 - val_acc: 0.8162\n",
      "Epoch 133/200\n",
      "3914/3914 [==============================] - 0s 22us/step - loss: 0.0843 - acc: 0.9699 - val_loss: 0.5847 - val_acc: 0.8162\n",
      "Epoch 134/200\n",
      "3914/3914 [==============================] - 0s 20us/step - loss: 0.0840 - acc: 0.9696 - val_loss: 0.5814 - val_acc: 0.8171\n",
      "Epoch 135/200\n",
      "3914/3914 [==============================] - 0s 25us/step - loss: 0.0841 - acc: 0.9696 - val_loss: 0.5884 - val_acc: 0.8152\n",
      "Epoch 136/200\n",
      "3914/3914 [==============================] - 0s 24us/step - loss: 0.0835 - acc: 0.9699 - val_loss: 0.5728 - val_acc: 0.8189\n",
      "Epoch 137/200\n",
      "3914/3914 [==============================] - 0s 24us/step - loss: 0.0836 - acc: 0.9699 - val_loss: 0.5870 - val_acc: 0.8143\n",
      "Epoch 138/200\n",
      "3914/3914 [==============================] - 0s 22us/step - loss: 0.0834 - acc: 0.9699 - val_loss: 0.5862 - val_acc: 0.8162\n",
      "Epoch 139/200\n",
      "3914/3914 [==============================] - 0s 21us/step - loss: 0.0831 - acc: 0.9704 - val_loss: 0.5915 - val_acc: 0.8152\n",
      "Epoch 140/200\n",
      "3914/3914 [==============================] - 0s 22us/step - loss: 0.0831 - acc: 0.9709 - val_loss: 0.5847 - val_acc: 0.8180\n",
      "Epoch 141/200\n",
      "3914/3914 [==============================] - 0s 27us/step - loss: 0.0828 - acc: 0.9714 - val_loss: 0.5921 - val_acc: 0.8134\n",
      "Epoch 142/200\n",
      "3914/3914 [==============================] - 0s 32us/step - loss: 0.0826 - acc: 0.9709 - val_loss: 0.5929 - val_acc: 0.8143\n",
      "Epoch 143/200\n",
      "3914/3914 [==============================] - 0s 25us/step - loss: 0.0826 - acc: 0.9701 - val_loss: 0.5873 - val_acc: 0.8162\n",
      "Epoch 144/200\n",
      "3914/3914 [==============================] - 0s 34us/step - loss: 0.0822 - acc: 0.9704 - val_loss: 0.5853 - val_acc: 0.8152\n",
      "Epoch 145/200\n",
      "3914/3914 [==============================] - 0s 30us/step - loss: 0.0824 - acc: 0.9704 - val_loss: 0.5870 - val_acc: 0.8152\n",
      "Epoch 146/200\n",
      "3914/3914 [==============================] - 0s 23us/step - loss: 0.0822 - acc: 0.9696 - val_loss: 0.5859 - val_acc: 0.8162\n",
      "Epoch 147/200\n",
      "3914/3914 [==============================] - 0s 29us/step - loss: 0.0818 - acc: 0.9704 - val_loss: 0.5814 - val_acc: 0.8180\n",
      "Epoch 148/200\n",
      "3914/3914 [==============================] - 0s 27us/step - loss: 0.0817 - acc: 0.9714 - val_loss: 0.5923 - val_acc: 0.8143\n",
      "Epoch 149/200\n",
      "3914/3914 [==============================] - 0s 31us/step - loss: 0.0816 - acc: 0.9706 - val_loss: 0.5901 - val_acc: 0.8143\n",
      "Epoch 150/200\n",
      "3914/3914 [==============================] - 0s 26us/step - loss: 0.0823 - acc: 0.9706 - val_loss: 0.5957 - val_acc: 0.8134\n",
      "Epoch 151/200\n",
      "3914/3914 [==============================] - 0s 30us/step - loss: 0.0815 - acc: 0.9699 - val_loss: 0.5953 - val_acc: 0.8143\n",
      "Epoch 152/200\n",
      "3914/3914 [==============================] - 0s 25us/step - loss: 0.0811 - acc: 0.9714 - val_loss: 0.5678 - val_acc: 0.8180\n",
      "Epoch 153/200\n",
      "3914/3914 [==============================] - 0s 26us/step - loss: 0.0812 - acc: 0.9709 - val_loss: 0.6076 - val_acc: 0.8106\n",
      "Epoch 154/200\n",
      "3914/3914 [==============================] - 0s 22us/step - loss: 0.0814 - acc: 0.9704 - val_loss: 0.5927 - val_acc: 0.8143\n",
      "Epoch 155/200\n",
      "3914/3914 [==============================] - 0s 25us/step - loss: 0.0807 - acc: 0.9711 - val_loss: 0.6000 - val_acc: 0.8143\n",
      "Epoch 156/200\n",
      "3914/3914 [==============================] - 0s 23us/step - loss: 0.0805 - acc: 0.9714 - val_loss: 0.5950 - val_acc: 0.8162\n",
      "Epoch 157/200\n",
      "3914/3914 [==============================] - 0s 25us/step - loss: 0.0804 - acc: 0.9722 - val_loss: 0.5910 - val_acc: 0.8152\n",
      "Epoch 158/200\n",
      "3914/3914 [==============================] - 0s 24us/step - loss: 0.0805 - acc: 0.9714 - val_loss: 0.5952 - val_acc: 0.8143\n",
      "Epoch 159/200\n",
      "3914/3914 [==============================] - 0s 22us/step - loss: 0.0800 - acc: 0.9719 - val_loss: 0.6062 - val_acc: 0.8124\n",
      "Epoch 160/200\n",
      "3914/3914 [==============================] - 0s 24us/step - loss: 0.0801 - acc: 0.9719 - val_loss: 0.6072 - val_acc: 0.8124\n",
      "Epoch 161/200\n",
      "3914/3914 [==============================] - 0s 23us/step - loss: 0.0798 - acc: 0.9722 - val_loss: 0.5967 - val_acc: 0.8162\n",
      "Epoch 162/200\n",
      "3914/3914 [==============================] - 0s 22us/step - loss: 0.0798 - acc: 0.9714 - val_loss: 0.6014 - val_acc: 0.8152\n",
      "Epoch 163/200\n",
      "3914/3914 [==============================] - 0s 23us/step - loss: 0.0796 - acc: 0.9719 - val_loss: 0.6087 - val_acc: 0.8134\n",
      "Epoch 164/200\n",
      "3914/3914 [==============================] - 0s 22us/step - loss: 0.0796 - acc: 0.9719 - val_loss: 0.6016 - val_acc: 0.8152\n",
      "Epoch 165/200\n",
      "3914/3914 [==============================] - 0s 26us/step - loss: 0.0798 - acc: 0.9716 - val_loss: 0.5959 - val_acc: 0.8143\n",
      "Epoch 166/200\n",
      "3914/3914 [==============================] - 0s 24us/step - loss: 0.0790 - acc: 0.9716 - val_loss: 0.6162 - val_acc: 0.8124\n",
      "Epoch 167/200\n",
      "3914/3914 [==============================] - 0s 28us/step - loss: 0.0794 - acc: 0.9716 - val_loss: 0.5923 - val_acc: 0.8171\n",
      "Epoch 168/200\n",
      "3914/3914 [==============================] - 0s 22us/step - loss: 0.0793 - acc: 0.9716 - val_loss: 0.6089 - val_acc: 0.8134\n",
      "Epoch 169/200\n",
      "3914/3914 [==============================] - 0s 20us/step - loss: 0.0787 - acc: 0.9719 - val_loss: 0.5958 - val_acc: 0.8171\n",
      "Epoch 170/200\n",
      "3914/3914 [==============================] - 0s 22us/step - loss: 0.0785 - acc: 0.9719 - val_loss: 0.6079 - val_acc: 0.8143\n",
      "Epoch 171/200\n",
      "3914/3914 [==============================] - 0s 22us/step - loss: 0.0787 - acc: 0.9724 - val_loss: 0.6029 - val_acc: 0.8171\n",
      "Epoch 172/200\n",
      "3914/3914 [==============================] - 0s 20us/step - loss: 0.0790 - acc: 0.9716 - val_loss: 0.6052 - val_acc: 0.8152\n",
      "Epoch 173/200\n",
      "3914/3914 [==============================] - 0s 21us/step - loss: 0.0781 - acc: 0.9724 - val_loss: 0.6172 - val_acc: 0.8134\n",
      "Epoch 174/200\n",
      "3914/3914 [==============================] - 0s 20us/step - loss: 0.0783 - acc: 0.9724 - val_loss: 0.5971 - val_acc: 0.8152\n",
      "Epoch 175/200\n",
      "3914/3914 [==============================] - 0s 22us/step - loss: 0.0780 - acc: 0.9724 - val_loss: 0.5973 - val_acc: 0.8180\n",
      "Epoch 176/200\n",
      "3914/3914 [==============================] - 0s 24us/step - loss: 0.0781 - acc: 0.9716 - val_loss: 0.6087 - val_acc: 0.8171\n",
      "Epoch 177/200\n",
      "3914/3914 [==============================] - 0s 21us/step - loss: 0.0779 - acc: 0.9722 - val_loss: 0.6090 - val_acc: 0.8152\n",
      "Epoch 178/200\n",
      "3914/3914 [==============================] - 0s 26us/step - loss: 0.0779 - acc: 0.9729 - val_loss: 0.6042 - val_acc: 0.8162\n",
      "Epoch 179/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3914/3914 [==============================] - 0s 22us/step - loss: 0.0779 - acc: 0.9732 - val_loss: 0.6179 - val_acc: 0.8152\n",
      "Epoch 180/200\n",
      "3914/3914 [==============================] - 0s 22us/step - loss: 0.0775 - acc: 0.9719 - val_loss: 0.5925 - val_acc: 0.8189\n",
      "Epoch 181/200\n",
      "3914/3914 [==============================] - 0s 26us/step - loss: 0.0773 - acc: 0.9716 - val_loss: 0.6139 - val_acc: 0.8134\n",
      "Epoch 182/200\n",
      "3914/3914 [==============================] - 0s 22us/step - loss: 0.0797 - acc: 0.9711 - val_loss: 0.6153 - val_acc: 0.8143\n",
      "Epoch 183/200\n",
      "3914/3914 [==============================] - 0s 26us/step - loss: 0.0782 - acc: 0.9742 - val_loss: 0.5843 - val_acc: 0.8199\n",
      "Epoch 184/200\n",
      "3914/3914 [==============================] - 0s 22us/step - loss: 0.0779 - acc: 0.9734 - val_loss: 0.6148 - val_acc: 0.8143\n",
      "Epoch 185/200\n",
      "3914/3914 [==============================] - 0s 24us/step - loss: 0.0772 - acc: 0.9727 - val_loss: 0.5848 - val_acc: 0.8199\n",
      "Epoch 186/200\n",
      "3914/3914 [==============================] - 0s 25us/step - loss: 0.0769 - acc: 0.9727 - val_loss: 0.6302 - val_acc: 0.8087\n",
      "Epoch 187/200\n",
      "3914/3914 [==============================] - 0s 21us/step - loss: 0.0773 - acc: 0.9737 - val_loss: 0.5902 - val_acc: 0.8180\n",
      "Epoch 188/200\n",
      "3914/3914 [==============================] - 0s 23us/step - loss: 0.0761 - acc: 0.9727 - val_loss: 0.6261 - val_acc: 0.8097\n",
      "Epoch 189/200\n",
      "3914/3914 [==============================] - 0s 26us/step - loss: 0.0767 - acc: 0.9724 - val_loss: 0.6122 - val_acc: 0.8134\n",
      "Epoch 190/200\n",
      "3914/3914 [==============================] - 0s 23us/step - loss: 0.0760 - acc: 0.9729 - val_loss: 0.6020 - val_acc: 0.8162\n",
      "Epoch 191/200\n",
      "3914/3914 [==============================] - 0s 24us/step - loss: 0.0760 - acc: 0.9729 - val_loss: 0.6105 - val_acc: 0.8162\n",
      "Epoch 192/200\n",
      "3914/3914 [==============================] - 0s 23us/step - loss: 0.0760 - acc: 0.9732 - val_loss: 0.6050 - val_acc: 0.8152\n",
      "Epoch 193/200\n",
      "3914/3914 [==============================] - 0s 24us/step - loss: 0.0756 - acc: 0.9729 - val_loss: 0.6041 - val_acc: 0.8162\n",
      "Epoch 194/200\n",
      "3914/3914 [==============================] - 0s 25us/step - loss: 0.0757 - acc: 0.9734 - val_loss: 0.6112 - val_acc: 0.8162\n",
      "Epoch 195/200\n",
      "3914/3914 [==============================] - 0s 21us/step - loss: 0.0757 - acc: 0.9737 - val_loss: 0.6016 - val_acc: 0.8189\n",
      "Epoch 196/200\n",
      "3914/3914 [==============================] - 0s 20us/step - loss: 0.0756 - acc: 0.9732 - val_loss: 0.6213 - val_acc: 0.8134\n",
      "Epoch 197/200\n",
      "3914/3914 [==============================] - 0s 23us/step - loss: 0.0754 - acc: 0.9734 - val_loss: 0.6109 - val_acc: 0.8162\n",
      "Epoch 198/200\n",
      "3914/3914 [==============================] - 0s 19us/step - loss: 0.0750 - acc: 0.9737 - val_loss: 0.6250 - val_acc: 0.8115\n",
      "Epoch 199/200\n",
      "3914/3914 [==============================] - 0s 22us/step - loss: 0.0761 - acc: 0.9714 - val_loss: 0.6152 - val_acc: 0.8124\n",
      "Epoch 200/200\n",
      "3914/3914 [==============================] - 0s 20us/step - loss: 0.0752 - acc: 0.9727 - val_loss: 0.6090 - val_acc: 0.8162\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(hidden_first, input_dim=n_components, activation='relu'))\n",
    "Dropout(dropout_size)\n",
    "model.add(Dense(hidden_second, activation='relu'))\n",
    "Dropout(dropout_size/2)\n",
    "model.add(Dense(hidden_third, activation='relu'))\n",
    "Dropout(dropout_size/3)\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_pca, y, batch_size=batch_size, epochs=epochs, shuffle=True, \n",
    "          validation_data=(X_test_pca[430:, :], y_test[430:]))\n",
    "\n",
    "Acc = []\n",
    "Tpr = []\n",
    "Tnr = []\n",
    "Ppv = []\n",
    "Npv = []\n",
    "F1 = []\n",
    "\n",
    "y_pred = model.predict(X_test_pca[430:, :]).round().reshape(-1)\n",
    "tp = (y_pred * y_test[430:]).sum() # predicted - 1, actual - 1\n",
    "tn = ((1-y_pred) * (1-y_test[430:])).sum() # predicted - 0, actual - 0\n",
    "fp = (y_pred * (1-y_test[430:])).sum() # predicted - 1, actual - 0\n",
    "fn = ((1-y_pred) * y_test[430:]).sum() # predicted - 0, actual - 1\n",
    "\n",
    "acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "tpr = tp / (tp + fn)\n",
    "tnr = tn / (tn + fp)\n",
    "ppv = tp / (tp + fp)\n",
    "npv = tn / (tn + fn)\n",
    "f1 = (2 * tpr * ppv) / (tpr + ppv)\n",
    "\n",
    "Acc.append(int(acc * 1000) / 10.0)\n",
    "Tpr.append(int(tpr * 1000) / 10.0)\n",
    "Tnr.append(int(tnr * 1000) / 10.0)\n",
    "Ppv.append(int(ppv * 1000) / 10.0)\n",
    "Npv.append(int(npv * 1000) / 10.0)\n",
    "F1.append(int(f1 * 1000) / 1000.0)\n",
    "\n",
    "Acc = np.array(Acc).astype(float)\n",
    "Tpr = np.array(Tpr).astype(float)\n",
    "Tnr = np.array(Tnr).astype(float)\n",
    "Ppv = np.array(Ppv).astype(float)\n",
    "Npv = np.array(Npv).astype(float)\n",
    "F1 = np.array(F1).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.785])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([81.6])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.715,\n",
       " 0.79,\n",
       " 0.738,\n",
       " 0.74,\n",
       " 0.755,\n",
       " 0.741,\n",
       " 0.793,\n",
       " 0.753,\n",
       " 0.752,\n",
       " 0.762,\n",
       " 0.753,\n",
       " 0.745,\n",
       " 0.742,\n",
       " 0.758,\n",
       " 0.754,\n",
       " 0.752,\n",
       " 0.755,\n",
       " 0.753,\n",
       " 0.742,\n",
       " 0.759,\n",
       " 0.744,\n",
       " 0.762,\n",
       " 0.753,\n",
       " 0.767,\n",
       " 0.753,\n",
       " 0.758,\n",
       " 0.762,\n",
       " 0.755,\n",
       " 0.764,\n",
       " 0.768,\n",
       " 0.763,\n",
       " 0.766,\n",
       " 0.762,\n",
       " 0.764,\n",
       " 0.779,\n",
       " 0.771,\n",
       " 0.786,\n",
       " 0.752,\n",
       " 0.763,\n",
       " 0.769,\n",
       " 0.767,\n",
       " 0.758,\n",
       " 0.776,\n",
       " 0.751,\n",
       " 0.776,\n",
       " 0.791,\n",
       " 0.776,\n",
       " 0.769]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[77.2,\n",
       " 81.8,\n",
       " 78.5,\n",
       " 78.8,\n",
       " 79.6,\n",
       " 78.7,\n",
       " 82.1,\n",
       " 79.4,\n",
       " 79.4,\n",
       " 80.1,\n",
       " 79.5,\n",
       " 79.1,\n",
       " 78.8,\n",
       " 79.8,\n",
       " 79.6,\n",
       " 79.5,\n",
       " 79.6,\n",
       " 79.5,\n",
       " 78.8,\n",
       " 80.0,\n",
       " 78.9,\n",
       " 80.1,\n",
       " 79.5,\n",
       " 80.5,\n",
       " 79.4,\n",
       " 79.9,\n",
       " 80.1,\n",
       " 79.6,\n",
       " 80.2,\n",
       " 80.5,\n",
       " 80.1,\n",
       " 80.4,\n",
       " 80.1,\n",
       " 80.2,\n",
       " 81.2,\n",
       " 80.6,\n",
       " 81.8,\n",
       " 79.4,\n",
       " 80.1,\n",
       " 80.5,\n",
       " 80.5,\n",
       " 79.8,\n",
       " 81.0,\n",
       " 79.4,\n",
       " 81.0,\n",
       " 81.9,\n",
       " 80.9,\n",
       " 80.5]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
